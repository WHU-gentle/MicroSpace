---
layout: post
#title:  "C++ frontend in Pytorch"
date: 2020-10-20
tags: Pytorch, C++
color: rgb(3,101,100)
#subtitle: 'Welcome to Jekyll!'
#cover: '../assets/pytorchDistributed.png'
---

# Motivation

Why you would want to use the C++ frontend instead of the Python one to begin with？

- **Low Latency Systems:**低延迟系统。Python由于Python interpreter的原因不易于管控，因此在面向例如reinforcement learning research等对性能和延迟要求严苛的应用中需要使用纯粹的C++库。

- **Highly Multithreaded Environments：**高度多线程的环境。由于Python的 Global Interpreter Lock (GIL)，其每次最多运行一个系统线程，虽然可以通过多处理机进行替代，但相比C++易于创建和使用的线程机制来说，Python还是有很多不足。尤其是对于并行化有强烈要求的模型，更能够获益于此。
- **Existing C++ Codebases**:现存的C++代码基础。如果你需要在已经存在的C++应用中比如3D graphics中使用机器学习方法，C++前端api可以支持统一的C++编程，避免频繁地在python和C++中切换交互。

The C++ frontend is not intended to compete with the Python frontend. It is meant to complement it. 

# Writing a Basic Application

## Install

```bash
wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip
unzip libtorch-shared-with-deps-latest.zip
```

## Code in C++

dcgan.cpp

```c++
#include <torch/torch.h>
#include <iostream>

int main() {
  torch::Tensor tensor = torch::eye(3);
  std::cout << tensor << std::endl;
}
```

## Build System

CMakeLists.txt

```cmake
cmake_minimum_required(VERSION 3.0 FATAL_ERROR)
project(dcgan)

find_package(Torch REQUIRED) # This instructs CMake to find the build configuration

add_executable(dcgan dcgan.cpp)
target_link_libraries(dcgan "${TORCH_LIBRARIES}")
set_property(TARGET dcgan PROPERTY CXX_STANDARD 14)
```

 You can also use Visual Studio project files, QMake, plain Makefiles or any other build environment you feel comfortable with.

现在最好把目录结构组成成如下：

```
dcgan/
  CMakeLists.txt
  dcgan.cpp
```

进入dcgan目录

```bash
mkdir build
cd build
cmake -DCMAKE_PREFIX_PATH=$PWD/../../libtorch ..
```

此处第一个参数应该是libtorch库地地址，第二个参数应该是cmake文件地目录。

执行出现了第一个错误：

```
cmake -DCMAKE_PREFIX_PATH=$PWD/../../libtorch ..
-- The CXX compiler identification is unknown
CMake Error at CMakeLists.txt:2 (project):
  No CMAKE_CXX_COMPILER could be found.

  Tell CMake where to find the compiler by setting either the environment
  variable "CXX" or the CMake cache entry CMAKE_CXX_COMPILER to the full path
  to the compiler, or to the compiler name if it is in the PATH.

-- Configuring incomplete, errors occurred!
```

看起来应该是没有编译器，解决办法：

```bash
sudo apt-get update 
sudo apt-get install -y build-essential
```

再次运行第二个错误：

```bash
CMake Error at CMakeLists.txt:4 (find_package):
  By not providing "FindTorch.cmake" in CMAKE_MODULE_PATH this project has
  asked CMake to find a package configuration file provided by "Torch", but
  CMake did not find one.

  Could not find a package configuration file provided by "Torch" with any of
  the following names:

    TorchConfig.cmake
    torch-config.cmake

  Add the installation prefix of "Torch" to CMAKE_PREFIX_PATH or set
  "Torch_DIR" to a directory containing one of the above files.  If "Torch"
  provides a separate development package or SDK, be sure it has been
  installed.
```

看起来是没有找到Torch地址，根据提示进行设置，在CMakeLists.txt中添加语句：

```cmake
set(CMAKE_PREFIX_PATH "$PWD/../../libtorch/share/cmake/Torch")
# ahead of find_package(Torch REQUIRED)
```

下一步，Build！

```
/dcgan/build$ cmake --build . --config Release
```

此时build文件夹下就有了二进制执行文件，运行它

```bash
/dcgan/build$ ./dcgan
 1  0  0
 0  1  0
 0  0  1
[ CPUFloatType{3,3} ]
```

# Defining the Custom Network

## What  a module usually contains

**Parameters:**

Parameters record gradients.Parameters are usually the trainable weights of your neural network.

**Buffers:**

Examples of buffers include means and variances for batch normalization.

**Submodules**:

A nested module is termed a *submodule*.

**forward() method:**

Implements the algorithm.

## Defining a Module and Registering Parameters

```c++
#include <torch/torch.h>

struct Net : torch::nn::Module {
  Net(int64_t N, int64_t M) {
    W = register_parameter("W", torch::randn({N, M}));
    b = register_parameter("b", torch::randn(M));
  }
  torch::Tensor forward(torch::Tensor input) {
    return torch::addmm(b, input, W);
  }
  torch::Tensor W, b;
};
```

## Registering Submodules and Traversing the Module Hierarchy

```c++
struct Net : torch::nn::Module {
  Net(int64_t N, int64_t M)
      : linear(register_module("linear", torch::nn::Linear(N, M))) {
    another_bias = register_parameter("b", torch::randn(M));
  }
  torch::Tensor forward(torch::Tensor input) {
    return linear(input) + another_bias;
  }
  torch::nn::Linear linear;
  torch::Tensor another_bias;
};
```

通过net.parameters()或者net.named_parameters()可以访问到模型的parameter。

下面测试其forward过程：

```c++
int main(){
  Net net(4, 5);
  std::cout << net.forward(torch::ones({2, 4})) << std::endl;
}
```

修改代码后重新运行时，先通过`make`进行编译，然后重新通过`./dcgan`执行。

```bash
$ ./dcgan
 0.1299  1.0980 -0.0584  1.4442  0.3597
 0.1299  1.0980 -0.0584  1.4442  0.3597
[ CPUFloatType{2,5} ]
```

## Module Ownership

对于上面使用submodule时 在构造函数后代码块之前 这种参数初始化方式，我其实是持有疑问的：既然放在{}里面和参数初始化表面效果是一样的，那为什么要采用这种形式。这个部分原文给出了解释。

**Description：**the ownership model refers to the way modules are stored and passed around – which determines who or what *owns* a particular module instance. 

**Reference ways**

-  **value semantics:**when passed to a function, can be either copied, moved (with `std::move`) or taken by reference or by pointer

```c++
struct Net : torch::nn::Module { };

void a(Net net) { }
void b(Net& net) { }
void c(Net* net) { }

int main() {
  Net net;
  a(net);
  a(std::move(net));
  b(net);
  c(&net);
}
```

- **reference semantics:** use `std::shared_ptr`,  the advantage of reference semantics is that it **reduces** the cognitive **overhead** of thinking about how modules must be passed to functions and how arguments must be declared.

```
struct Net : torch::nn::Module {};
void a(std::shared_ptr<Net> net) { }
int main() {
  auto net = std::make_shared<Net>();
  a(net);
}
```

The module holder API is the recommended way of defining modules with the C++ frontend.